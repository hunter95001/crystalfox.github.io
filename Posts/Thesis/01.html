<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>FaceForensics++: Learning to Detect Manipulated Facial Images</title>
  <link rel="stylesheet" type="text/css" href="../../CSS/Style.css">
  <link rel="stylesheet" type="text/css" href="../../CSS/Post.css">
  <link rel="stylesheet" type="text/css" href="../../CSS/Attach.css">
  <link rel="shortcut icon" href="../../Image/favicon.ico">

  <script src="//code.jquery.com/jquery-1.11.0.min.js"></script>
  <script type="text/javascript">
    $(document).ready(function() {
      $("#sider").load("../../include/sider.html"); // 원하는 파일 경로를 삽입하면 된다
      $("#footers").load("../../include/footer.html"); // 추가 인클루드를 원할 경우 이런식으로 추가하면 된다
    });
  </script>
</head>

<body>
  <div id="wrapper">
    <div id="sider"></div>
    <div id="main-wrapper">
      <div style="maring:30px">
        <font size="5" color="#f0f0f0">Div 영역입니다.</font>
      </div>
      <div class="main-post">
        <div class="main-title">
          <h1>FaceForensics++: Learning to Detect Manipulated Facial Images </h1>
          <h2>Thesis</h2>
          <p class="main-title-time">작성일 : 2020-05-28</p>
        </div>
        <hr>
        
        <!--  본문 시작-->
	      
       <a class=" posts" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Rossler_FaceForensics_Learning_to_Detect_Manipulated_Facial_Images_ICCV_2019_paper.pdf" target="_blank"><img class="link"src="../../../Image/link-icon.png?raw=true">FaceForensics++: Learning to Detect Manipulated Facial Images</a>
 <br>
        
        
        <p class="posts">

	     <h2 class="posts" >1. Introduction </h2>
평가<br
검출 방법의 평가를 표준화하기 위해 안면 조작 검출에 대한 자동 벤치마크<br>
-벤치마크는 공개적으로 이용할 수 있으며 180만 개 이상의 조작된 이미지의 데이터베이스와 숨겨진 테스트 세트를 포함하고 있다.<br>
위변조 탐지를 전례 없는 정확도로 향상시키고, 인간 관찰자를 확실히 능가한다<br>
​<br>
디지털 미디어 포렌식 분야에는 위변조 탐지에 대한 벤치마크가 부족<br>
때문에 무작위 압축과 무작위 차원으로 4가지 조작 방법을 현실적인 시나리오로 고려한 자동화된 벤치마크를 제안한다.<br>
벤치마크는 다음과 같은 조건을 따른다.<br>
• 사람의 평가 기준선을 포함한 표준화된 비교를 위해 무작위 압축에 따른 얼굴 조작 감지를 위한 자동화된 벤치마크.<br>
• 1,000개의 깨끗한 비디오(즉, 실제) 출처와 대상 검증자료를 제공하여 학습된 학습을 가능하게 한다.<br>
• 다양한 시나리오에서 state-of-the-art hand-crafted and learned forgery detectors에 대한 광범위한 평가<br>
• 안면 조작에 맞춘 a state-of-the-art forgery detection 방법<br>
​<br>
1.인간의 얼굴을 재구성하고 추적하는 것은 이러한 편집 접근법의 기초가 되는 컴퓨터 비전에서 잘 관찰된 분야다.<br>
2.사람의 얼굴은 메시지를 강조하거나 심지어 자신의 권리로 메시지를 전달할 수 있기 때문에, 얼굴은 인간 의사소통에 중심적인 역할을 한다.<br>
​<br>
얼굴 조작 방법 (Face2Face)<br>
1. 얼굴 표정 조작과<br>
2. 얼굴 정체성 조작<br>
​<br>
편집기술<br>
1. 포토샵과 같은 도구를 사용해 얼굴을 수동으로 편집<br>
2. face swapping [Snapchat, Snow, Soda 등]<br>
​<br>
딥페이크<br>
face swapping + 딥러닝<br>
​<br>
고전적인 컴퓨터 그래픽 기반 방법 - Face2Face, FaceSwap<br>
학습 접근 방법 DeepFake, NeuralTexture<br>
​<br>
2. Related Work<br>
Face Manipulation Methods:<br>
Zollhofer - 구강 움직임이 생성되는 사람의 새로운 비디오를 자동으로 만들기 위한 영상 기반 접근법 비디오 재작성(Video Rewrite)을 제시.<br>
Garrido - 본래의 표현을 보존하면서 배우의 얼굴을 대신하는 유사한 시스템을 제시<br>
[품질의 3D 얼굴 캡처 기술을 사용하여 입 움직임에 맞게 배우의 얼굴을 사진처럼 변화]<br>
Thies - 실시간 표현 전달 시연(Face2Face)<br>
[1.source와 대상 배우의 3D 모델을 재구성하고 추적 2.source면의 추적된 변형은 대상 면 모델에 적용 3.바뀐 얼굴을 원래의 대상 비디오 위에 조합]<br>
​<br>
Kim - 이미지와 이미지 간 변환 네트워크를 학습하여 얼굴의 컴퓨터 그래픽 렌더링을 실제 이미지로 변환<br>
​<br>
Suwajanakorn -오디오와 입술 모션의 매핑 [Face2Face와 유사]<br>
Averbuch-Elor - 2D왜곡하여 만든 source 대상자의 표현에 맞게 이미지를 변형시키는 재현 방법 Bringing Portraits to Life [Face2Face와 유사]<br>
Lu - 생성적 적성 네트워크(GANs)는 얼굴 노화를 적용하거나, 새로운 관점을 생성하기 위해 피부색과 같은 얼굴 속성을 변경하는 데 사용<br>
​<br>
Karras - GANs의 점진적인 성장을 통해 영상 화질을 개선하여 얼굴의 고품질 합성<br>
​<br>
Face2Face: 고급 실시간 얼굴 재현 시스템으로, 일반 비디오 스트림에서 얼굴 움직임을 변경할 수 있다<br>
[3D 모델 재구성과 이미지 기반 렌더링 기술을 결합하여 그들의 출력 - 가상현실에서도 eye-tracking과 reenactment의 결합을 통해 full body로 확대 가능]<br>
​<br>
NeuralTextures: 순수한 image-to-image translation network 대신에 렌더링 네트워크와 함께 신경 텍스처를 최적화하여 재현 결과를 계산<br>
[구강 부위에서 더 뚜렷한 결과]<br>
​<br>
Deep Feature Interpolation: 나이, 콧수염, 미소 등과 같은 얼굴 속성을 바꾸는 데 효과적. 유사한 속성 보간 결과는 Fader Networks을 적용<br>
​<br>
멀티미디어 포렌식:<br>
멀티미디어 포렌식(Multimed Forgency)은 내장된 보안 계획의 도움 없이 이미지 또는 비디오의 신뢰성, 출처 및 입증성을 보장하는 것을 목표로한다.<br>
최근에는 지도학습과, 비지도학습을 통한 CNN에 기반을 둔 해결책에 초점을 맞춘다.<br>
동영상의 경우 삭제되거나 중복된 프레임, 다양한 보간 유형, 복사 이동 조작 또는 크로마 키 구성과 같은 작업 주체는 비교적 적은 노력으로 만들 수 있는 조작을 탐지하는 데 초점을 맞추고 있다.<br>
컴퓨터가 생성한 얼굴들과 원본 얼굴들을 구별하는 조작들에 대해서 morphed faces, face splicing, face swapping 그리고 DeepFakes가 있다.<br>
얼굴 조작 감지를 위해, 일부 접근방식은 눈 깜빡임이나 색, 질감, 모양 단서 등과 같은 합성 과정에서 발생하는 특정 인위결과물을 이용<br>
미세한 불일치를 포착하기 위해 학습된 깊은 네트워크를 제안<br>
But 견고성은 해결되지않음!<br>
압축과 크기 조정과 같은 작업은 데이터에서 조작 흔적을 제거하는 것으로 알려져 있다.<br>
이를 위해 당사의 데이터 세트는 실제와 같은 실제 시나리오 즉, 다양한 품질 수준으로 조작되고 압축된 비디오를 포함하도록 설계되어 있다.<br>
이렇게 크고 다양한 데이터 세트를 이용할 수 있게 되면 연구자들이 접근법을 벤치마킹하고 얼굴 이미지를 위한 더 나은 위조 탐지기를 개발할 수 있다.<br>
​<br>
법의학 분석 데이터 세트:<br>
-국립표준기술원(NIST)은 약 5만 개의 위조 영상(현지 및 글로벌 조작)과 약 500개의 위조 영상으로 구성된 일반 영상 조작을 가장 광범위한 데이터 세트를 공개<br>
-우리는 기존 데이터 세트보다 더 큰 크기의 4,000개의 가짜 비디오에서 180만개 이상의 이미지를 포함하는 데이터베이스를 구축했다.<br>
​<br>
3. Large-Scale Facial Forgery Database<br>
본 문서의 핵심 기여는 예비 FaceForenics 데이터셋을 확장하는 FaceForenics++ 데이터셋이다.<br>
YouTube에서 다운로드 한 509, 914개의 이미지가 포함된 비디오에서 4 가지 자동 첨단 얼굴 조작 방법을 활용 합니다<br>
​<br>
FaceSwap - 얼굴 부위를 소스 비디오에서 타깃 비디오로 전송하기 위한 그래픽 기반의 접근법<br>
- 희소 검출된 얼굴 랜드마크를 기반으로 얼굴 부위를 추출합니다.<br>
- 이 모델은 입력 이미지의 텍스처를 사용하여 투영 된 모양과 지역화 된 랜드마크 간의 차이를 최소화하여 대상 이미지로 역 투영됩니다.<br>
- 렌더링된 모델이 이미지와 혼합되어 색상 보정이 적용된다.<br>
​<br>
DeepFakes -딥러닝을 기반으로 한 얼굴 교체<br>
- 각각 소스와 대상 면의 학습 이미지를 재구성하도록 학습된 공유 인코더를 가진 두 개의 자동 인코더를 기반으로 한다.<br>
- 얼굴 검출기는 얼굴 이미지를 자르고 정렬<br>
- 가짜 이미지를 만들기 위해, source 면의 학습된 인코더와 디코더를 대상 면에 적용<br>
- 자동 인코더 출력은 Poisson 영상 편집을 사용하여 이미지의 나머지 부분과 혼합<br>
* 잡지식 [온라인 사이트에서 DeepFakes라는 사람이 연예인 얼굴을 이용한 포르노를 개시하여 그때부터 DeepFakes라고 불림]<br>
​<br>
Face2Face - 상자의 정체성을 유지하면서 소스 영상의 표정을 대상 영상에 전송하는 얼굴 재현 시스템<br>
- 수동 키프레임 선택과 함께 두 개의 비디오 입력 스트림을 기반<br>
- 프레임들은 다른 조명과 표현에서 얼굴을 다시 동기화하는 데 사용할 수 있는 면의 조밀한 재구성에 사용<br>
- 각 비디오를 사전 처리 패스로 처리하고, 첫 번째 프레임을 사용하여 임시 얼굴 아이덴티티(즉, 3D 모델)를 획득하고 나머지 프레임에 대한 표현을 추적<br>
- 접근에 필요한 키프레임을 선택하기 위해 얼굴의 왼쪽과 오른쪽 각도가 있는 프레임을 자동으로 선택<br>
-이러한 아이덴티티 재구성을 바탕으로 Face2Face의 원래 구현에서와 같이 표현, 딱딱한 포즈 및 조명 파라미터를 프레임별로 계산하기 위해 전체 비디오를 추적한다.<br>
-각 프레임의 소스 표현 파라미터(즉, 76 Blendshape 계수)를 대상 비디오로 전송하여 재현 비디오 출력을 생성한다.<br>
​<br>
NeuralTextures - 렌더링 접근법의 예로서 안면 재연<br>
- 렌더링 네트워크를 포함한 대상자의 신경 질감을 배우기 위해 원본 비디오 데이터를 사용한다.<br>
- 상대적 손실과 조합하여 측광학적 재구성 손실로 학습된다.<br>
- Pix2Pix에 사용된 패치 기반 GAN 손실 함수를 적용한다.<br>
- 구강 부위에 해당하는 표정만 수정한다 [눈 부위는 변하지 않는다.]<br>
​<br>
Postprocessing - Video Quality<br>
SNS나 영상공유사이트에서 많이 사용하는 H.264 코덱을 이용해 영상을 압축한다.<br>
고품질 비디오를 생성하기 위해 시각적으로 손실이 거의 없는 HQ(정정률 정량화 매개변수 23)로 표시된 적외선 압축을 사용한다.<br>
저품질 동영상(LQ )은 40의 정량화를 사용하여 제작된다.<br>
​<br>
4. Forgery Detection<br>
위조 탐지는 조작된 비디오의 프레임 별 이진 분류 문제로 간주했다.<br>
​<br>
4.1. Forgery Detection of Human Observers<br>
위조 탐지 과제에서 인간의 성과를 평가하기 위해 주로 컴퓨터공학과 대학생으로 구성된 204명의 참가자를 대상으로 사용자연구를 실시했다. 이것은 자동 위조 탐지 방법의 기준을 형성한다.<br>
​<br>
Layout of the User Study<br>
이미지 1장당 제한된 시간만 사용하는 시나리오를 모방하기 위해 무작위로 2, 4, 6초 후에 이미지를 숨긴다.<br>
우리는 이 연구를 참가자 한 명당 몇 분밖에 걸리지 않도록 설계했고, 참석자 한 명당 60개의 이미지를 보여주었고, 그 결과 12240개의 인간 결정이 수집되었다.<br>
​<br>
Evaluation<br>
원 영상 평균 68.69%, 고화질 66.57%, 저화질 영상 58.73%로 정확도가 낮아진다.<br>
​<br>
4.2. Automatic Forgery Detection Methods<br>
비디오에서 얼굴을 추적하고 이미지의 얼굴 영역을 추출합니다.<br>
추적된 면의 중심 주위에 보수적 인 자르기 (1.3 배 확대)를 사용하여 재구성된 면을 둘러 쌉니다.<br>
일반 조작 탐지, 컴퓨터 생성 대 자연 이미지 탐지 및 얼굴 변조 탐지를 위해 법의학 커뮤니티에서 사용되는 학습 기반 방법을 고려하고 있다.<br>
​<br>
4.2.1 Detection based on Steganalysis Features:<br>
Fridrich 연구원들의 방법에 따라 steganalysis 기능에서 탐지를 평가합니다.<br>
전체 기능 길이가 162 인 고역 이미지의 가로 및 세로 방향을 따라 4 픽셀 패턴에서 동시 발생합니다.<br>
그런 다음이 기능을 사용하여 선형 SVM 분류기를 훈련시킵니다.<br>
원시 이미지에서 사람의 정확도를 크게 뛰어 넘지 만 압축에 대처하기 어려워 화질이 낮은 비디오의 경우 사람의 성능보다 정확도가 낮습니다<br>
​<br>
4.2.2 Detection based on Steganalysis Features:<br>
학습 된 기능을 감지하기 위해 분류 작업을 해결하기 위해 문헌에서 알려진 5 가지 네트워크 아키텍처를 평가합니다.<br>
(1) Cozzolino은 Steganalysis 기능을 이전 섹션에서 CNN 기반 네트워크로 캐스트 했습니다. 대규모 네트워크에서 이 네트워크를 미세 조정 합니다<br>
(2) 제한된 컨볼루션 레이어는 이미지의 높은 수준의 콘텐츠를 억제하도록 특별히 설계되었습니다. 이전 방법과 유사하게, 중앙 128 × 128 작물을 입력으로 사용합니다.<br>
(3) Rahmouni는 네 가지 통계 (평균, 분산, 최대 및 최소)를 계산하는 글로벌 풀링 계층으로 다른 CNN 아키텍처를 채택합니다.<br>
(4) MesoInception-4는 비디오의 얼굴 훼손을 감지하기 위해 InceptionNet에서 영감을 얻은 CNN 기반 네트워크입니다.<br>
네트워크에는 두 개의 시작 모듈과 max-pooling 레이어가 인터레이스 된 two classic convolution layers가 있습니다.<br>
그 후 two fully-connected layers가 있습니다.<br>
고전적인 엔트로피 손실 대신에, 저자는 실제 라벨과 예측 된 라벨 사이의 평균 제곱 오차를 제안합니다.<br>
얼굴 이미지의 크기를 네트워크의 입력 인 256 × 256으로 조정한다<br>
(5) XceptionNet은 잔류 연결과 분리 가능한 회선을 기반으로 ImageNet에 대해 훈련 된 전통적인 CNN입니다.<br>
우리는 최종 fully connected layer를 두 개의 출력으로 교체하여 작업으로 옮깁니다.<br>
다른 레이어는 ImageNet 가중치로 초기화됩니다.<br>
새로 삽입 된 fully connected layer를 설정하기 위해 모든 가중치를 최종 레이어에 고정하고 네트워크에 3 개의 epochs를 사전 훈련시킵니다.<br>
이 단계 후에, 우리는 15 개 더 많은 epochs를 위해 네트워크를 훈련시키고 검증 정확도에 기초하여 최고의 성능 모델을 선택합니다<br>
<br>
Comparison of our Forgery Detection Variants:<br>
모든 접근법은 원시 입력 데이터에서 매우 높은 성능을 달성하지만 압축 된 비디오, 특히 수작업으로 만들어진 기능 및 얕은 CNN 아키텍처의 경우 성능은 낮다.<br>
신경망은 이러한 상황을 보다 잘 처리 할 수 있으며 XceptionNet은 약한 압축에 대한 강력한 결과를 달성하면서도 낮은 품질의 이미지에서 합리적인 성능을 유지하면서 ImageNet에 대한 사전 교육과 더 큰 네트워크 용량의 이점을 제공합니다.<br>
우리의 자동 탐지기는 사람의 성능을 크게 능가 합니다<br>
도메인별 정보가 없는 XceptionNet 은 정확도가 상당히 낮지만<br>
도메인별 정보를 가진 XceptionNet은 최상의 성능을 보여줍니다.<br>
실험은 모든 검출 방법이 GAN 기반 신경 조직 접근 방법에서 정확도를 낮춘다는 것을 보여줍니다.<br>

Forgery Detection of GAN-based methods:<br>
모든 검출 방법이 GAN 기반 신경 조직 접근 방법에서 정확도를 낮춘다는 것을 보여줍니다.<br>
	      
Evaluation of the Training Corpus Size:<br>
저화질 비디오 영상에 특히 중요한 훈련 영상 수에 따라 증가한다.<br>
<br>
5. Benchmark<br>
1000 개의 비디오를 추가 수집하고 4 가지 조작 방법 각각에 대해 섹션 3과 유사한 방식으로 비디오의 일부를 조작했습니다.<br>
업로드된 비디오(예: SNS)는 다양한 방식으로 후처리되므로, 우리는 현실적인 조건을 보장하기 위해 선택된 모든 비디오(예: 알 수 없는 이미지 리사이징, 압축 방법, 비트 레이트)를 여러 번 모호하게 한다.<br>
1000개의 이미지 세트를 수집하는데, 각각의 이미지는 조작 방법이나 원본 영상 중 하나에서 무작위로 찍은 것이다<br>
벤치마크 시나리오가 교육 데이터베이스와 다르기 때문에 모델의 전체 성능은 특히 깨끗한 이미지 감지 정밀도에 비해 낮습니다<br>

6. Discussion & Conclusion.<br>
현재의 최첨단 얼굴 이미지 조작 방법은 시각적으로 놀라운 결과를 보여 주지만, 훈련 된 위조 탐지기로 탐지 할 수 있음을 보여줍니다.<br>
인간과 손수 작업한 기능이 어려움을 보이는 학습 기반 접근 방식으로 저품질 비디오의 까다로운 사례도 해결할 수 있다는 점이 특히 고무적입니다.<br>
이 논문에서 우리는 최첨단 조작 방법의 검출 가능성에 대한 압축의 영향에 초점을 맞추고 후속 작업에 대한 표준화 된 벤치마크를 제안합니다.<br>
특히, 전이 학습은 법의학 커뮤니티에 큰 관심을 가지고 있습니다.<br>
새로운 조작 방법이 등장함에 따라 훈련 데이터가 거의 없거나 전혀 없는 가짜를 탐지 할 수 있는 방법이 개발되어야합니다.<br>
보여지는 것처럼 한 소스 조작 도메인에 대한 지식이 다른 타겟 도메인으로 전송 되는 법의학 전이 학습 작업에 이미 사용되었습니다.<br>
우리는 데이터 세트와 벤치마크가 디지털 미디어 법의학 분야, 특히 얼굴 위조에 중점을 둔 미래의 연구를 위한 디딤돌이 되기를 희망합니다.<br>
<br>
7. Acknowledgement<br>
기타등등 감사합니다.<br>
공군 연구소 및 국방 고급 연구 프로젝트 기관이 후원하는 연구를 기반으로 합니다.<br>
미국 정부는 저작권 표시에도 불구하고 정부 목적으로 재판을 복제하고 배포 할 수 있습니다.<br>
        </p>
        

	      
        
            
        
      </div><!--main-post-->
    </div><!-- main-wrapper 본문 끝-->
  </div><!-- wrapper-->

  <div id="footers"></div>

</body>

</html>
